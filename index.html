<!DOCTYPE HTML>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhihe Lu (Lucas)</title>

  <meta name="author" content="Zhihe Lu">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <style>
    p {font-size: 18px;font-family: "Times New Roman", Times, serif;}

    a {font-size: 18px;font-family: "Times New Roman", Times, serif;}

    br {font-size: 18px;font-family: "Times New Roman", Times, serif;}

    em {font-size: 18px;font-family: "Times New Roman", Times, serif;}

    strong {font-size: 18px;font-family: "Times New Roman", Times, serif;}

    papertitle {font-size: 18px;font-family: "Times New Roman", Times, serif;}

    name {font-size: 30px; font-family: "Times New Roman", Times, serif;}

    heading {font-size: 30px; font-family: "Times New Roman", Times, serif;}
  </style>
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:65%;vertical-align:middle">
              <p style="text-align:center";style="line-height:1.5">
                <name>Zhihe Lu (卢治合)</name>
              </p>
              <p style="line-height:1.5">
                Currently, I am a Postdoc researcher at National University of Singapore, working with Prof. <a href="https://sites.google.com/site/sitexinchaowang/?pli=1">Xinchao Wang</a>. Before, I finished the PhD degree at University of Surrey under the supervision of Prof. <a href="https://www.surrey.ac.uk/people/tao-xiang">Tao Xiang</a> and Prof. <a href="https://www.surrey.ac.uk/people/yi-zhe-song">Yi-Zhe Song</a>.
                and the Master's degree at the Institute of Automation, Chinese Academy of Sciences, supervised by Prof. <a href="https://rhe-web.github.io/">Ran He</a>.
              </p>
              <p style="line-height:1.5">
                My research interest centers around the following areas:<br />
                <strong>Computer Vision</strong>: Object Recognition and Semantic Segmentation<br />
                <strong>Transfer Learning</strong>: Unsupervised Domain Adaptation, Source-free Domain Adaptation and Test-time Adaptation<br />
                <strong>Few-shot Learning</strong>: Meta-learning and Generalized Few-shot Models<br />
                <strong>Effcient Tuning of Foundation Models</strong>: Effcient Tuning of Vision-Language Models
              </p>
              <p style="text-align:center">
                <a href="mailto:zhihelu.academic@gmail.com">Email</a> &nbsp/&nbsp
                <a href="resume/homepage.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=X4LKIhgAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/zhiheLu">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:45%;max-width:45%">
              <a href="images/zhihe-circle.png"><img style="width:60%;max-width:60%" alt="profile photo" src="images/zhihe-circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Recent News</heading>
            </td>
          </tr>
          
          <tr>
            <td style="padding:2.5%;width:65%;vertical-align:middle">
              <em>2024.09.26: One paper accepted on NeurIPS 2024.</em> <br />
              <em>2024.07.16: Two papers accepted on ACM MM 2024.</em> <br />
              <em>2024.07.01: Two papers accepted on ECCV 2024.</em> <br />
              <em>2024.06.10: Gave a talk on <a href="https://www.zdzheng.xyz/MORE2024/">ACM ICMR 2024</a>.</em> <br />
              <em>2024.05.02: One paper accepted on ICML 2024.</em> <br />
              <em>2024.04.21: One paper accepted on PR 2024.</em> <br />
              <details>
                <summary><strong>Old News</strong></summary>
                <em>2023.09.22: Two papers accepted on NeurIPS 2023.</em> <br />
                <em>2023.07.11: One paper accepted on TIP 2023.</em> <br />
                <em>2023.05.26: One paper accepted on TIP 2023.</em> <br />
                <em>2023.02.28: One paper accepted on CVPR 2023.</em>
              </details>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading href="publication.html">Selected Publications</heading>
            </td>
          </tr>
        <!-- </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/envlm.png" alt="envlm_png" width="250" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <a href="https://arxiv.org/pdf/2311.17091">
                <papertitle>Beyond Sole Strength: Customized Ensembles for Generalized Vision-Language Models</papertitle>
              </a>
              <br>
                  <strong>Zhihe Lu</strong>,
                  <a>Jiawang Bai</a>,
                  <a>Xin Li</a>,
                  <a>Zeyu Xiao</a>,
                  <a>Xinchao Wang</a>
              <br>
              <em>ICML, 2024</em>
              <br>
              <a href="https://github.com/zhiheLu/Ensemble_VLM">code</a>
              <p style="line-height:1.5">The first investigation of ensemble learning for VLMs.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/graph.png" alt="graph_png" width="250" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <a href="https://openreview.net/pdf?id=YmEDnMynuO">
                <papertitle>GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph</papertitle>
              </a>
              <br>
                  <a>Xin Li<sup>*</sup></a>,
                  <a>Dongze Lian<sup>*</sup></a>,
                  <strong>Zhihe Lu<sup>*</sup></strong>,
                  <a>Jiawang Bai</a>,
                  <a>Zhibo Chen</a>,
                  <a>Xinchao Wang</a>
              <br>
              <em>* Equal Contribution</em>
              <br>
              <br>
              <em>NeurIPS, 2023</em>
              <br>
              <a href="https://github.com/lixinustc/GraphAdapter">code</a>
              <p style="line-height:1.5">Introduce knowledge graph for tuning vision and language models.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/fda.png" alt="fda_png" width="250" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <a href="https://openreview.net/pdf?id=eKFrXWb0sT">
                <papertitle>Frequency-enhanced Data Augmentation for Vision-and-Language Navigation</papertitle>
              </a>
              <br>
                  <a>Keji He</a>,
                  <a>Chenyang Si</a>,
                  <strong>Zhihe Lu</strong>,
                  <a>Yan Huang</a>,
                  <a>Liang Wang</a>,
                  <a>Xinchao Wang</a>
              <br>
              <em>NeurIPS, 2023</em>
              <br>
              <a href="https://github.com/hekj/FDA">code</a>
              <p style="line-height:1.5">A work to explore the significance of high-frequency information for enhanced Vision-and-Language Navigation.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/sfda.png" alt="pcn_png" width="250" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/10189399">
                <papertitle>Uncertainty-aware Source-free Domain Adaptive Semantic Segmentation</papertitle>
              </a>
              <br>
                  <strong>Zhihe Lu</strong>,
                  <a>Da Li</a>,
                  <a>Yi-Zhe Song</a>,
                  <a>Tao Xiang</a>,
                  <a>Timothy M. Hospedales</a>
              <br>
              <em>TIP, 2023</em>
              <br>
              <p style="line-height:1.5">An uncertainty-aware solution for SFDASS.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/pcn.png" alt="pcn_png" width="250" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <a href="https://arxiv.org/pdf/2210.08290.pdf">
                <papertitle>Prediction Calibration for Generalized Few-shot Semantic Segmentation</papertitle>
              </a>
              <br>
                  <strong>Zhihe Lu</strong>,
                  <a>Sen He</a>,
                  <a>Da Li</a>,
                  <a>Yi-Zhe Song</a>,
                  <a>Tao Xiang</a>
              <br>
              <em>TIP, 2023</em>
              <br>
              <p style="line-height:1.5">Investigating the feature-prediction covariance based Transformer for calibrating the biases in GFSS.</p>
            </td>
          </tr>
          
           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TaskRes.png" alt="taskres_png" width="250" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <a href="https://arxiv.org/pdf/2211.10277.pdf">
                <papertitle>Task Residual for Tuning Vision-Language Models</papertitle>
              </a>
              <br>
                  <a>Tao Yu<sup>*</sup></a>,
                  <strong>Zhihe Lu<sup>*</sup></strong>,
                  <a>Xin Jin</a>,
                  <a>Zhibo Chen</a>,
                  <a>Xinchao Wang</a>
              <br>
              <em>* Equal Contribution</em>
              <br>
              <br>
              <em>CVPR, 2023</em>
              <br>
              <a href="https://github.com/geekyutao/TaskRes">code</a>
              <p style="line-height:1.5">A simple yet effective tuning method for vision and language models.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cwt_frame.jpg" alt="cwt_png" width="250" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <a href="https://arxiv.org/pdf/2108.03032.pdf">
                <papertitle>Simpler is Better: Few-shot Semantic Segmentation with Classifier Weight Transformer</papertitle>
              </a>
              <br>
                  <strong>Zhihe Lu</strong>,
                  <a>Sen He</a>,
                  <a>Xiatian Zhu</a>,
                  <a>Li Zhang</a>,
                  <a>Yi-Zhe Song</a>,
                  <a>Tao Xiang</a>
              <br>
              <em>ICCV, 2021</em>
              <br>
              <a href="https://github.com/zhiheLu/CWT-for-FSS">code</a>
              <p style="line-height:1.5">A novel training pipeline for few-shot segmentation with classifier weight transformer.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/star_frame.jpg" alt="star_png" width="250" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Lu_Stochastic_Classifiers_for_Unsupervised_Domain_Adaptation_CVPR_2020_paper.pdf">
                <papertitle>Stochastic Classifiers for Unsupervised Domain Adaptation</papertitle>
              </a>
              <br>
                  <strong>Zhihe Lu</strong>,
                  <a>Yongxin Yang</a>,
                  <a>Xiatian Zhu</a>,
                  <a>Cong Liu</a>,
                  <a>Yi-Zhe Song</a>,
                  <a>Tao Xiang</a>
              <br>
              <em>CVPR, 2020</em>
              <br>
              <a href="https://github.com/zhiheLu/STAR_Stochastic_Classifiers_for_UDA">code</a>
              <p style="line-height:1.5">A novel way to use infinite number of classifiers without extra parameters to identify misaligned regions.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/gafp_gan.jpg" alt="gafp_png" width="250" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <a href="https://dl.acm.org/doi/pdf/10.1145/3240508.3240647">
                <papertitle>Conditional Expression Synthesis with Face Parsing Transformation</papertitle>
              </a>
              <br>
                  <strong>Zhihe Lu</strong>,
                  <a>Tanhao Hu</a>,
                  <a>Lingxiao Song</a>,
                  <a>Zhaoxiang Zhang</a>,
                  <a>Ran He</a>
              <br>
              <em>ACM MM, 2018</em>
              <br>
              <p style="line-height:1.5">A Couple-Agent Face Parsing based Generative Adversarial Network (CAFP-GAN) that unites the knowledge of facial semantic regions and controllable expression signals.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/g2_gan.jpg" alt="g2_png" width="250" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <a href="https://arxiv.org/abs/1712.03474">
                <papertitle>Geometry Guided Adversarial Facial Expression Synthesis</papertitle>
              </a>
              <br>
                  <a>Lingxiao Song</a>,
                  <strong>Zhihe Lu</strong>,
                  <a>Ran He</a>,
                  <a>Zhenan Sun</a>,
                  <a>Tieniu Tan</a>
              <br>
              <em>ACM MM, 2018</em>
              <br>
              <p style="line-height:1.5"> A Geometry-Guided Generative Adversarial Network (G2-GAN) was proposed for photorealistic and identity-preserving facial expression synthesis.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/face_survey.jpg" alt="face_survey_png" width="250" style="border-style: none">
            </td>
            <td width="70%" valign="middle">
              <a href="https://arxiv.org/abs/1706.04717">
                <papertitle>Recent Progress of Face Image Synthesis</papertitle>
              </a>
              <br>
              <strong>Zhihe Lu</strong>,
              <a>Zhihang Li</a>,
              <a>Jie Cao</a>,
              <a>Ran He</a>,
              <a>Zhenan Sun</a>
              <br>
              <em>ACPR, 2017</em>
              <br>
              <p style="line-height:1.5"> A very early survey for face image synthesis.</p>
            </td>
          </tr>

        </tbody></table> -->

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Professional Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="70%" valign="center" style="font-size: 20px;font-family: 'Times New Roman', Times, serif;">
              <p style="line-height:1.5"> <strong>Journal Reviewers:</strong> TPAMI, IJCV, TIP, PR, etc.</p>
              <p style="line-height:1.5"> <strong>Conference Reviewers:</strong> CVPR, ICCV, ECCV, ICML, NeurIPS, ICLR, etc.</p>
            </td>
          </tr>
        </tbody></table>
          <p style="text-align:right;font-size:15px;">
            Thanks for <a style="font-size:15px"; href="https://jonbarron.info/">Jon Barron</a>'s website sharing.
          </p>
      </td>
    </tr>
  </table>
</body>

</html>
